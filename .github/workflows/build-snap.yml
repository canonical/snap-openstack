name: Build Snap

on:
  workflow_call:
    outputs:
      snap:
        description: "Filename of the built snap artifact"
        value: local-${{ jobs.build.outputs.snap }}

jobs:
  build:
    name: Build snap
    runs-on: ubuntu-latest
    outputs:
      snap: ${{ steps.snapcraft.outputs.snap }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Build snap locally
        uses: canonical/action-build@v1.3.0
        id: snapcraft

      - name: Upload locally built snap artifact
        uses: actions/upload-artifact@v4
        with:
          name: local-${{ steps.snapcraft.outputs.snap }}
          path: ${{ steps.snapcraft.outputs.snap }}

  functional-test:
    needs: build
    name: Functional test
    runs-on: [self-hosted, large, noble, x64]
    strategy:
      fail-fast: false
      matrix:
        flavor: [storage, no-storage]
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Download snap artifact
        id: download
        uses: actions/download-artifact@v4
        with:
          name: local-${{ needs.build.outputs.snap }}
      - name: test
        run: |
          set -x
          export COLUMNS=256

          # Check docker, containerd and remove them if exists
          sudo apt remove --purge docker.io containerd runc -y
          sudo rm -rf /run/containerd

          roles="control,compute"
          if [ "${{ matrix.flavor }}" == "storage" ]; then
            roles="$roles,storage"
            sudo mkdir -p /dev/disk/by-id/ || true
            function loop_device() {
                local free_device
                local id_path="/dev/disk/by-id/$(basename $1)"
                local ld_path="$1.img"
                sudo dd if=/dev/zero of="$ld_path" bs=4096 count=305175
                sync
                free_device=$(sudo losetup --show --find "$ld_path")
                wipefs --all "$free_device" 1>&2
                sgdisk --zap-all "$free_device" 1>&2
                sudo ln -s "$free_device" "$id_path"
                echo $id_path
            }
            sudo snap install yq
            lds="$(loop_device /ld1),$(loop_device /ld2),$(loop_device /ld3)"
            yq e -i ".core.config.microceph_config.\"$(hostname -f)\".osd_devices = \"$lds\"" .github/assets/testing/edge.yml
          fi

          # Allow lxd controller to reach to k8s controller on loadbalancer ip
          # sudo nft insert rule ip filter FORWARD tcp dport 17070 accept
          # sudo nft insert rule ip filter FORWARD tcp sport 17070 accept
          # With above rules, got the following error:
          # api.charmhub.io on 10.152.183.182:53: server misbehaving
          # Accept all packets filtered for forward
          sudo nft chain ip filter FORWARD '{policy accept;}'

          sudo snap remove --purge lxd
          sudo snap install --channel 3.6 juju

          sudo snap install  ${{ needs.build.outputs.snap }} --dangerous
          sudo snap connect openstack:juju-bin juju:juju-bin
          openstack.sunbeam prepare-node-script --bootstrap | bash -x
          sudo snap connect openstack:dot-local-share-juju
          sudo snap connect openstack:dot-config-openstack
          sudo snap connect openstack:dot-local-share-openstack

          # Even though `--topology single --database single` is not used in the
          # single-node tutorial, explicitly speficy it here to force the single
          # mysql mode.
          # The tutorial assumes ~16 GiB of memory where Sunbeam selects the singe
          # mysql single mysql mode automatically. And self-hosted runners may
          # have more than 32 GiB of memory where Sunbeam selects the multi mysql
          # mode instead. So we have to override the Sunbeam's decision to be
          # closer to the tutorial scenario.
          sg snap_daemon "openstack.sunbeam cluster bootstrap --role "$roles" --manifest .github/assets/testing/edge.yml --accept-defaults --topology single --database single"
          sg snap_daemon "openstack.sunbeam cluster list"
          # Note: Moving configure before enabling caas just to ensure caas images are not downloaded
          # To download caas image, require ports to open on firewall to access fedora images.
          sg snap_daemon "openstack.sunbeam configure --accept-defaults --openrc demo-openrc"
          sg snap_daemon "openstack.sunbeam launch --name test"
          # The cloud-init process inside the VM takes ~2 minutes to bring up the
          # SSH service after the VM gets ACTIVE in OpenStack
          sleep 300
          source demo-openrc
          openstack console log show --lines 200 test
          demo_floating_ip="$(openstack floating ip list -c 'Floating IP Address' -f value | head -n1)"
          ssh -oStrictHostKeyChecking=no -oUserKnownHostsFile=/dev/null -i ~/snap/openstack/current/sunbeam "ubuntu@${demo_floating_ip}" true

          sg snap_daemon "openstack.sunbeam enable orchestration"
          sg snap_daemon "openstack.sunbeam enable loadbalancer"
          sg snap_daemon "openstack.sunbeam enable dns testing.github."
          sg snap_daemon "openstack.sunbeam disable dns"
          sg snap_daemon "openstack.sunbeam disable loadbalancer"
          sg snap_daemon "openstack.sunbeam disable orchestration"

          # Vault has storage requirements > 15G
          # Commenting as CI servers might not have enough disk space
          # sg snap_daemon "openstack.sunbeam enable vault --dev-mode"
          # sg snap_daemon "openstack.sunbeam enable secrets"
          # sg snap_daemon "openstack.sunbeam disable secrets"
          # sg snap_daemon "openstack.sunbeam disable vault"

          # Disable caas temporarily while MySQL memory gets adjusted
          # sg snap_daemon "openstack.sunbeam enable caas"
          # sg snap_daemon "openstack.sunbeam enable validation"
          # If smoke tests fails, logs should be collected via sunbeam command in "Collect logs"
          # sg snap_daemon "openstack.sunbeam validation run smoke"
          # sg snap_daemon "openstack.sunbeam validation run --output tempest_validation.log"
          # sg snap_daemon "openstack.sunbeam disable caas"
          # sg snap_daemon "openstack.sunbeam disable validation"

          sg snap_daemon "openstack.sunbeam enable telemetry"
          # Commenting observability as storage requirements ~6G 
          # sg snap_daemon "openstack.sunbeam enable observability embedded"
          # Commented disabling observability due to LP#1998282
          # sg snap_daemon "openstack.sunbeam disable observability embedded"
          # sg snap_daemon "openstack.sunbeam disable telemetry"

          # Commenting features as storage is full in CI machines
          # sg snap_daemon "openstack.sunbeam enable resource-optimization"
          # sg snap_daemon "openstack.sunbeam enable instance-recovery"
          # Disable IR as the consul pods are stuck in getting terminated
          # sg snap_daemon "openstack.sunbeam disable instance-recovery"
          # sg snap_daemon "openstack.sunbeam disable resource-optimization"

      - name: Collect logs
        if: always()
        run: |
          kubectl="k8s kubectl"
          mkdir -p logs
          cp -rf $HOME/snap/openstack/common/logs/*.log logs/
          models=$(juju models --format json | jq -r .models[].name)
          for model in $models;
          do
            name=$(echo $model | cut -d/ -f2);
            juju status -m $model -o logs/$name.yaml;
            cat logs/$name.yaml;
            juju debug-log -m $model --replay &> logs/$name-debug-log.txt || echo "Not able to get logs for model $model"
            for pod in $(sudo $kubectl get pods -n $name -o=jsonpath='{.items[*].metadata.name}');
            do
              sudo $kubectl logs --ignore-errors -n $name --all-containers $pod &> logs/$pod.log || echo "Not able to get log for $pod"
            done
            sudo $kubectl -n $name get po -o yaml &> logs/$name-po.yaml
            sudo $kubectl -n $name get pvc -o yaml &> logs/$name-pvc.yaml
            sudo k8s kubectl -n $name get CSIStorageCapacity -o yaml &> logs/$name-storage-capacity.yaml
          done
          sudo $kubectl get pv -o yaml &> logs/pv.yaml
          sudo $kubectl get nodes -o yaml &> logs/nodes.yaml
          sudo k8s kubectl -n kube-system get CSIStorageCapacity -o yaml &> logs/storage-capacity.yaml

          sudo df -h &> logs/df_h.txt
          # if test -f tempest_validation.log; then cp tempest_validation.log logs/; fi
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sunbeam_logs-${{ matrix.flavor}}
          path: logs
          retention-days: 30
      - name: Setup tmate session
        if: ${{ failure() && runner.debug }}
        uses: canonical/action-tmate@main
